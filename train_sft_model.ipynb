{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import traceback\n",
    "from accelerate import Accelerator, InitProcessGroupKwargs\n",
    "from accelerate.utils import pad_across_processes, broadcast\n",
    "from collections import defaultdict\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datasets import load_dataset, load_from_disk, DatasetDict, Dataset, concatenate_datasets\n",
    "from datetime import datetime,  timedelta\n",
    "import time\n",
    "from functools import partial\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from src.python_engine import run_python_code\n",
    "from src.utils import set_seed, floatify, compute_ETA\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelForCausalLM, get_linear_schedule_with_warmup, AdamW, get_constant_schedule_with_warmup\n",
    "import wandb\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import signal\n",
    "from contextlib import contextmanager\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from accelerate import notebook_launcher\n",
    "from accelerate.utils import DeepSpeedPlugin\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "tqdm = partial(tqdm, ncols=0, leave=False)\n",
    "\n",
    "\n",
    "TIMEOUT = 10\n",
    "instruction=None\n",
    "cot_trigger=None\n",
    "answer_trigger=None\n",
    "def setup_cot(src_name):\n",
    "    assert src_name in ['gsm8k', 'mathqa', 'svamp', 'mathqa-numeric', 'zhouyi']\n",
    "    global instruction\n",
    "    global cot_trigger\n",
    "    global answer_trigger\n",
    "    # Complete output is in this form: f'{instruction}{question.strip()}{cot_trigger}{answer_cot.strip()}'\n",
    "    instruction = 'Question:\\n'\n",
    "    cot_trigger = '\\nAnswer reasoning:\\n'\n",
    "    answer_trigger = '\\n因此，答案是：'\n",
    "    return \n",
    "\n",
    "post_process_final_answer_fn_mapper = {\n",
    "    'gsm8k': lambda x: float(x.replace(',','').strip()),\n",
    "    'svamp': lambda x: float(x.replace(',','').strip()),\n",
    "    'mathqa': lambda x: x.lower().replace('\"','').replace(\"'\",'').strip(),\n",
    "    'mathqa-numeric': lambda x: float(x),\n",
    "    'zhouyi': lambda x: x.strip(),\n",
    "}\n",
    "### the answer_cot is a list of answer_cot\n",
    "post_process_answer_cot_fn_mapper = {\n",
    "    ('python', 'gsm8k'): lambda answer_cot: [floatify(res) for res in run_python_code(programs=answer_cot, TIMEOUT=TIMEOUT)],\n",
    "    ('python', 'svamp'): lambda answer_cot: [floatify(res) for res in run_python_code(programs=answer_cot, TIMEOUT=TIMEOUT)],\n",
    "    ('python', 'mathqa'): lambda answer_cot: [str(res).lower().replace('\"','').replace(\"'\",'').strip() for res in run_python_code(programs=answer_cot, TIMEOUT=TIMEOUT)],\n",
    "    ('python', 'mathqa-numeric'): lambda answer_cot: [floatify(res) for res in run_python_code(programs=answer_cot, TIMEOUT=TIMEOUT)],\n",
    "    ('nl', 'gsm8k'): lambda answer_cot: [floatify(res.split(answer_trigger)[-1].strip()) for res in answer_cot],\n",
    "    ('nl', 'svamp'): lambda answer_cot: [floatify(res.split(answer_trigger)[-1].strip()) for res in answer_cot],\n",
    "    ('nl', 'mathqa'): lambda answer_cot: [res.split(answer_trigger)[-1].lower().replace('\"','').replace(\"'\",'').strip() for res in answer_cot],\n",
    "    ('nl', 'mathqa-numeric'): lambda answer_cot: [floatify(res.split(answer_trigger)[-1].strip()) for res in answer_cot],\n",
    "    ('nl', 'zhouyi'): lambda answer_cot: [res.split(answer_trigger)[-1].strip() for res in answer_cot],\n",
    "}\n",
    "compare_answer_fn_mapper = {\n",
    "    'gsm8k': lambda extracted_ans, target_answer: abs(extracted_ans - target_answer) <= 1e-2,\n",
    "    'svamp': lambda extracted_ans, target_answer: abs(extracted_ans - target_answer) <= 1e-2,\n",
    "    'mathqa': lambda extracted_ans, target_answer: extracted_ans == target_answer,\n",
    "    'mathqa-numeric': lambda extracted_ans, target_answer: abs(extracted_ans - target_answer) <= 1e-2,\n",
    "    'zhouyi': lambda extracted_ans, target_answer: extracted_ans == target_answer,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# trainer\n",
    "# 方式2：使用类装饰器\n",
    "def with_accelerator(cls):\n",
    "    def wrapper(acc):\n",
    "        global accelerator\n",
    "        accelerator = acc\n",
    "        return cls()\n",
    "    return wrapper\n",
    "\n",
    "@with_accelerator\n",
    "class Trainer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def prepare_datasets_and_data_loaders(self, args, tokenizer):\n",
    "        # 确保所有进程同步开始准备数据\n",
    "        # accelerator.wait_for_everyone()\n",
    "        \n",
    "        with accelerator.main_process_first():\n",
    "            raw_dataset = DatasetDict({\n",
    "                'train': Dataset.from_list(json.load(open(args['train_file'],'r'))),\n",
    "                'test': Dataset.from_list(json.load(open(args['test_file'],'r'))),\n",
    "            })\n",
    "            accelerator.print('Raw data:', raw_dataset)\n",
    "            src_name = raw_dataset['train'][0]['item_id'].split('_')[0]  # e.g., gsm8k_0, gsm8k_1, gsm8k_2, ...\n",
    "            setup_cot(src_name)\n",
    "            accelerator.print('Using instruction:', instruction)\n",
    "            accelerator.print('Using cot_trigger:', cot_trigger)\n",
    "            accelerator.print('Using answer_trigger:', answer_trigger)\n",
    "            def tokenize_fn(batch, args, tokenizer):\n",
    "                assert tokenizer.eos_token_id is not None, (tokenizer.eos_token_id, tokenizer.eos_token)\n",
    "                new_batch = defaultdict(list)\n",
    "                all_keys = list(batch.keys())\n",
    "                for item_values in zip(*(batch[k] for k in all_keys)):\n",
    "                    item = {k: item_values[i] for i, k in enumerate(all_keys)}\n",
    "                    item_id, question, answer_value, answer_cot = \\\n",
    "                            item['item_id'], \\\n",
    "                            item['question'], \\\n",
    "                            item['answer_value'], \\\n",
    "                            item.get('answer_cot', None), \\\n",
    "\n",
    "                    question = question.strip()\n",
    "                    if answer_value is not None:\n",
    "                        answer_value = answer_value.strip()\n",
    "\n",
    "                    if answer_cot is not None:\n",
    "                        answer_cot = answer_cot.strip()\n",
    "                        if args['engine'] == 'nl':\n",
    "                            answer_cot += f'{answer_trigger}{answer_value}'\n",
    "\n",
    "                    input = f'{instruction}{question}{cot_trigger}'\n",
    "                    output = f'{answer_cot}'\n",
    "                    prefix_text = f'{instruction}{question}{cot_trigger}'\n",
    "\n",
    "                    input_encode = tokenizer(input, add_special_tokens=False)\n",
    "                    output_encode = tokenizer(output, add_special_tokens=False)\n",
    "                    prefix_encode = tokenizer(prefix_text, add_special_tokens=False)\n",
    "\n",
    "                    input_ids = input_encode['input_ids'] + output_encode['input_ids'] + [tokenizer.eos_token_id]\n",
    "                    labels = [-100]*len(input_encode['input_ids']) + output_encode['input_ids'] + [tokenizer.eos_token_id]\n",
    "                    attention_mask = [1]* len(input_ids)\n",
    "                    prefix = prefix_encode['input_ids']\n",
    "                    prefix_attention_mask = prefix_encode['attention_mask']\n",
    "\n",
    "                    # Truncation\n",
    "                    input_ids_max_length = len(input_ids)\n",
    "                    # assert input_ids_max_length <= args['max_input_length'], input_ids_max_length\n",
    "                    input_ids = input_ids[:args['max_input_length']]\n",
    "                    labels = labels[:args['max_input_length']]\n",
    "                    attention_mask = attention_mask[:args['max_input_length']]\n",
    "                    prefix = prefix[:args['max_input_length']]\n",
    "                    prefix_attention_mask = prefix_attention_mask[:args['max_input_length']]\n",
    "\n",
    "                    ##\n",
    "                    new_batch['input_ids'].append(input_ids)\n",
    "                    new_batch['labels'].append(labels)\n",
    "                    new_batch['attention_mask'].append(attention_mask)\n",
    "                    new_batch['prefix'].append(prefix)\n",
    "                    new_batch['prefix_attention_mask'].append(prefix_attention_mask)\n",
    "                    ##\n",
    "                    new_batch['item_id'].append(item_id)\n",
    "                    new_batch['question'].append(question)\n",
    "                    new_batch['answer_cot'].append(answer_cot)\n",
    "                    new_batch['answer_value'].append(answer_value)\n",
    "                    new_batch['input_ids_max_length'].append(input_ids_max_length)\n",
    "                \n",
    "                return new_batch\n",
    "\n",
    "            tokenized_dataset = DatasetDict({\n",
    "                mode: dataset.map(\n",
    "                    tokenize_fn, fn_kwargs={'args': args, 'tokenizer': tokenizer}, batched=True, remove_columns=dataset.column_names, \n",
    "                    num_proc=8, load_from_cache_file=False\n",
    "                ) for mode, dataset in raw_dataset.items()})\n",
    "            accelerator.print('Processed data:', tokenized_dataset)\n",
    "            for mode, dataset in tokenized_dataset.items():\n",
    "                accelerator.print(mode, f'{mode}_input_ids_max_length', max(dataset['input_ids_max_length']))\n",
    "\n",
    "            if accelerator.is_main_process and args['wandb_log']:\n",
    "                wandb.config.update({\n",
    "                    \"src_name\": src_name,\n",
    "                    \"instruction\": instruction,\n",
    "                    \"cot_trigger\": cot_trigger,\n",
    "                    \"answer_trigger\": answer_trigger,\n",
    "                    \"raw_dataset\": str(raw_dataset),\n",
    "                    \"tokenized_dataset\": str(tokenized_dataset),\n",
    "                    \"train_input_ids_max_length\": max(tokenized_dataset['train']['input_ids_max_length']),\n",
    "                    \"test_input_ids_max_length\": max(tokenized_dataset['test']['input_ids_max_length']),\n",
    "                })\n",
    "\n",
    "        def collate_fn(batch, args, tokenizer):\n",
    "            max_input_length = max([len(item['input_ids']) for item in batch])\n",
    "            max_target_length = max([len(item['labels']) for item in batch])\n",
    "            max_prefix_length = max([len(item['prefix']) for item in batch])\n",
    "            input_ids  = []\n",
    "            attention_mask  = []\n",
    "            labels, labels_left_padded  = [], []\n",
    "            prefix_left_padded  = []\n",
    "            prefix_attention_mask_left_padded  = []\n",
    "            for item in batch:\n",
    "                input_ids.append(item['input_ids'] + [tokenizer.pad_token_id]*(max_input_length - len(item['input_ids'])))\n",
    "                attention_mask.append(item['attention_mask'] + [0]*(max_input_length - len(item['attention_mask'])))\n",
    "                labels.append(item['labels'] + [-100]*(max_target_length - len(item['labels'])))\n",
    "\n",
    "                labels_left_padded.append([-100]*(max_target_length - len(item['labels'])) + item['labels'])\n",
    "                prefix_left_padded.append([tokenizer.pad_token_id]*(max_prefix_length - len(item['prefix'])) + item['prefix'])\n",
    "                prefix_attention_mask_left_padded.append([0]*(max_prefix_length - len(item['prefix_attention_mask'])) + item['prefix_attention_mask'])\n",
    "            forward_kwargs = {\n",
    "                'input_ids': torch.LongTensor(input_ids),\n",
    "                'attention_mask': torch.BoolTensor(attention_mask),\n",
    "                'labels': torch.LongTensor(labels)\n",
    "            }\n",
    "            generate_prefix_kwargs = {\n",
    "                'input_ids': torch.LongTensor(prefix_left_padded),\n",
    "                'attention_mask': torch.BoolTensor(prefix_attention_mask_left_padded),\n",
    "                'labels': torch.LongTensor(labels_left_padded)\n",
    "            }\n",
    "            return {\n",
    "                'forward_kwargs': forward_kwargs,\n",
    "                'generate_prefix_kwargs': generate_prefix_kwargs,\n",
    "            }\n",
    "\n",
    "        train_dataloader = DataLoader(\n",
    "            tokenized_dataset['train'], \n",
    "            # sampler=train_sampler,  # 使用分布式采样器替代shuffle\n",
    "            batch_size=args['batch_size'], \n",
    "            num_workers=args['num_workers'], \n",
    "            pin_memory=True, \n",
    "            collate_fn=partial(collate_fn, args=args, tokenizer=tokenizer),\n",
    "            drop_last=True\n",
    "        )\n",
    "                            \n",
    "        test_dataloader = DataLoader(tokenized_dataset['test'], shuffle=False, batch_size=args['eval_batch_size'], num_workers=args['num_workers'], pin_memory=True, \n",
    "                            collate_fn=partial(collate_fn, args=args, tokenizer=tokenizer))\n",
    "        \n",
    "        # accelerator.wait_for_everyone()                    \n",
    "        return (tokenized_dataset['train'], train_dataloader), (tokenized_dataset['test'], test_dataloader)\n",
    "\n",
    "    def do_checkpoint(self, args, model, tokenizer, save_path, global_step):\n",
    "        try:\n",
    "            # 确保进程按顺序打印\n",
    "            for rank in range(self.accelerator.num_processes):\n",
    "                if accelerator.process_index == rank:\n",
    "                    accelerator.print(f\"\\n{'='*50}\")\n",
    "                    accelerator.print(f\"[进程 {rank} 的参数信息]\")\n",
    "                    accelerator.print(f\"{'='*50}\\n\")\n",
    "                    \n",
    "                    # 1. 打印总参数量\n",
    "                    total_params = sum(p.numel() for p in model.parameters())\n",
    "                    accelerator.print(f\"总参数量: {total_params}\")\n",
    "                                        \n",
    "        except Exception as e:\n",
    "            accelerator.print(f\"[进程 {accelerator.process_index}] 打印参数信息失败: {e}\")\n",
    "            return False\n",
    "                \n",
    "        try:\n",
    "            accelerator.wait_for_everyone()\n",
    "            accelerator.print(f\"Rank {accelerator.process_index} do_checkpoint 同步成功\")\n",
    "        except Exception as e:\n",
    "            accelerator.print(f\"Rank {accelerator.process_index} do_checkpoint 同步失败: {e}\")\n",
    "            return False\n",
    "        # 保存config tokenizer \n",
    "        try:\n",
    "            if accelerator.is_main_process:\n",
    "                config = AutoConfig.from_pretrained(args[\"model_name_or_path\"], trust_remote_code=True)\n",
    "                config.save_pretrained(args[\"model_dir\"])\n",
    "                tokenizer.save_pretrained(args[\"model_dir\"])\n",
    "        except:\n",
    "            accelerator.print(f\"Rank {accelerator.process_index} do_checkpoint config tokenizer 保存失败\")\n",
    "            return False\n",
    "        try:\n",
    "            if accelerator.is_main_process:\n",
    "                unwrapped_model = accelerator.unwrap_model(model)\n",
    "            # 打印state_dict\n",
    "            accelerator.print(f\"{'='*50} unwrapped_model.named_parameters()\")\n",
    "            for name, param in unwrapped_model.named_parameters():\n",
    "                accelerator.print(f\"参数 {name}: shape {param.shape}\")\n",
    "            accelerator.print(f\"{'='*50} model.named_parameters()\")\n",
    "            for name, param in model.named_parameters():\n",
    "                accelerator.print(f\"参数 {name}: shape {param.shape}\")\n",
    "            accelerator.print(f\"{'='*50}\")\n",
    "            \n",
    "            accelerator.print(f\"Rank {accelerator.process_index} do_checkpoint state_dict 收集成功\")\n",
    "        except:\n",
    "            accelerator.print(f\"Rank {accelerator.process_index} do_checkpoint state_dict 收集失败\")\n",
    "            return False\n",
    "        try:        \n",
    "            # if accelerator.is_main_process:\n",
    "            unwrapped_model.save_pretrained(\n",
    "                save_path,\n",
    "                is_main_process=accelerator.is_main_process,\n",
    "                save_function=accelerator.save,\n",
    "                # 且分为n个模型文件\n",
    "                max_shard_size=\"2GB\",  # 添加此参数来控制分片大小\n",
    "                safe_serialization=True,  # 使用安全的序列化方式\n",
    "                state_dict = accelerator.get_state_dict(model)\n",
    "                )\n",
    "            accelerator.print('save checkpoint success!')\n",
    "            accelerator.wait_for_everyone()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            accelerator.print(f\"Rank {accelerator.process_index} 保存失败: {e}\")\n",
    "            # accelerator.wait_for_everyone()\n",
    "            return False\n",
    "\n",
    "    def train_one_epoch(self, args, model, train_dataset, train_dataloader, optimizer, scheduler, tokenizer,\n",
    "                        global_step, test_dataset, test_dataloader, \n",
    "                        prefix, epoch, best_eval_log_dict, summary_log_dict, most_recent_ckpts_paths):\n",
    "        \n",
    "        model_dir = args['model_dir']\n",
    "        clip_grad_norm = args.get('clip_grad_norm', None)\n",
    "        evaluating_step_freq = args.get('evaluating_step_freq', None)\n",
    "        logging_step_freq = args.get('logging_step_freq', None)\n",
    "        saving_step_freq = args.get('saving_step_freq', None)\n",
    "        model.train()\n",
    "        epoch_result_dict = defaultdict(list)\n",
    "        gradient_accumulation_steps = args['gradient_accumulation_steps']\n",
    "        optimizer.zero_grad()\n",
    "        accelerator.print(f\"Rank {accelerator.process_index} 进入 train_one_epoch\")\n",
    "        \n",
    "        # 打印train_dataloader\n",
    "        accelerator.print(f\"Rank {accelerator.process_index} train_dataloader: {train_dataloader}\")\n",
    "        # 确保在开始循环前同步RNG状态\n",
    "        try:\n",
    "            accelerator.wait_for_everyone()\n",
    "            accelerator.print(f\"Rank {accelerator.process_index} train_one_epoch 同步成功\")\n",
    "        except Exception as e:\n",
    "            accelerator.print(f\"Rank {accelerator.process_index} train_one_epoch 同步失败: {e}\")\n",
    "            return False\n",
    "        pbar = tqdm(total=len(train_dataloader), desc=f'Train Loop [{accelerator.process_index}]')\n",
    "        \n",
    "        # with tqdm(enumerate(train_dataloader), total=len(train_dataloader), disable=not accelerator.is_main_process, desc='Train Loop') as t:\n",
    "        for idx, batch in  enumerate(train_dataloader):\n",
    "            try:\n",
    "                accelerator.wait_for_everyone()\n",
    "                accelerator.print(f\"Rank {accelerator.process_index} train_one_epoch 第{idx}批次同步成功\")\n",
    "            except Exception as e:\n",
    "                accelerator.print(f\"Rank {accelerator.process_index} train_one_epoch 第{idx}批次同步失败: {e}\")\n",
    "                try:\n",
    "                    accelerator.wait_for_everyone()\n",
    "                    accelerator.print(f\"Rank {accelerator.process_index} train_one_epoch 第{idx}批次重新同步成功\")\n",
    "                except Exception as e:\n",
    "                    accelerator.print(f\"Rank {accelerator.process_index} train_one_epoch 第{idx}批次重新同步失败: {e}\")\n",
    "            try:\n",
    "                # 前向传播\n",
    "                output = model(**batch['forward_kwargs'])\n",
    "                loss = output[0]\n",
    "                \n",
    "                # 缩放损失以适应梯度累积\n",
    "                loss = loss / gradient_accumulation_steps\n",
    "                \n",
    "                # 反向传播\n",
    "                accelerator.backward(loss)\n",
    "                \n",
    "                # 记录指标\n",
    "                result_dict, extra = {}, None\n",
    "                \n",
    "                # 在累积足够步数后更新\n",
    "                if (idx + 1) % gradient_accumulation_steps == 0:\n",
    "                    if clip_grad_norm is not None:\n",
    "                        accelerator.clip_grad_norm_(model.parameters(), clip_grad_norm)\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    \n",
    "                    # 更新全局步数\n",
    "                    global_step += 1\n",
    "                    \n",
    "                    # 记录训练损失\n",
    "                    epoch_result_dict['loss'].append(loss.item() * gradient_accumulation_steps)\n",
    "                    for k, v in result_dict.items():\n",
    "                        epoch_result_dict[k].append(v)\n",
    "\n",
    "                    # 评估逻辑\n",
    "                    eval_log_dict = {}\n",
    "                    is_best = False\n",
    "                    # if evaluating_step_freq is not None and global_step % evaluating_step_freq == 0:\n",
    "                    if evaluating_step_freq :\n",
    "                        evaluate_result_dict = {\n",
    "                            f'Eval.Gen.{k}': v \n",
    "                            for k, v in evaluate_generation(args, model, test_dataset, test_dataloader, tokenizer).items()\n",
    "                        }\n",
    "                        eval_log_dict.update(evaluate_result_dict)\n",
    "                        if eval_log_dict['Eval.Gen.value_accuracy'] > best_eval_log_dict.get('Eval.Gen.value_accuracy_best', 0):\n",
    "                            is_best = True\n",
    "                            best_eval_log_dict['Eval.Gen.value_accuracy_best'] = eval_log_dict['Eval.Gen.value_accuracy']\n",
    "                        if 'Eval.Gen.value_accuracy' not in summary_log_dict:\n",
    "                            summary_log_dict['Eval.Gen.value_accuracy'] = []\n",
    "                        summary_log_dict['Eval.Gen.value_accuracy'].append(eval_log_dict['Eval.Gen.value_accuracy'])\n",
    "\n",
    "                    # 日志记录\n",
    "                    train_log_dict = {}\n",
    "                    if logging_step_freq is not None and global_step % logging_step_freq == 0:\n",
    "                        train_log_dict = {\n",
    "                            f'T.{k}': sum(v)/len(v) if isinstance(v, list) else v \n",
    "                            for k, v in epoch_result_dict.items()\n",
    "                        }\n",
    "                    \n",
    "                    if eval_log_dict or train_log_dict:\n",
    "                        log_dict = {\n",
    "                            'lr': scheduler.get_last_lr()[0], \n",
    "                            **train_log_dict, \n",
    "                            **eval_log_dict, \n",
    "                            **best_eval_log_dict\n",
    "                        }\n",
    "                        if accelerator.is_main_process and args['wandb_log']:\n",
    "                            wandb.log(log_dict, step=global_step)\n",
    "                            log_dict = {'wandb': args['wandb_project'] + '|' + args['wandb_run_name'], **log_dict}\n",
    "                        log_dict = {k: f'{v:.5g}' if isinstance(v, float) else v for k,v in log_dict.items()}\n",
    "                        accelerator.print(f\"{prefix}[E={epoch}/{args['n_epochs']}, S={global_step}] {log_dict}\")\n",
    "\n",
    "                    # 保持记录数量\n",
    "                    for k, v in epoch_result_dict.items():\n",
    "                        if len(v) > 1:\n",
    "                            epoch_result_dict[k] = v[-1:]\n",
    "                accelerator.print(f\"Rank {accelerator.process_index} 训练批次 {idx} 成功\")\n",
    "            except Exception as e:\n",
    "                accelerator.print(f\"[进程 {accelerator.process_index}] 批次 {idx} 出错: {e}\")\n",
    "                accelerator.print(traceback.format_exc())\n",
    "                continue\n",
    "        # Metric summary:\n",
    "        epoch_result_dict = {k:(sum(v)/len(v) if isinstance(v, list) else v) for k, v in epoch_result_dict.items()}\n",
    "        # 更新进度条\n",
    "        if accelerator.is_main_process:\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "        accelerator.print(f\"Rank {accelerator.process_index} 训练epoch {epoch} 结束\")\n",
    "        return epoch_result_dict, global_step, evaluate_result_dict\n",
    "\n",
    "    def evaluate_generation(self, args, model, dataset, dataloader, tokenizer):\n",
    "        # return {'value_accuracy': 0}\n",
    "\n",
    "        model.eval()\n",
    "        predictions = []\n",
    "        targets = []\n",
    "        for idx, batch in tqdm(\n",
    "            enumerate(dataloader), total=len(dataloader), disable=not accelerator.is_main_process,\n",
    "            desc='Evaluation Gen Loop'):\n",
    "            output_ = accelerator.unwrap_model(model).generate(\n",
    "                **batch['generate_prefix_kwargs'],\n",
    "                max_length=args['max_gen_length'],\n",
    "                output_scores=True,\n",
    "                return_dict_in_generate=True,\n",
    "                num_beams=1,\n",
    "                use_cache=True,\n",
    "                do_sample=False,\n",
    "                pad_token_id=tokenizer.pad_token_id,\n",
    "                eos_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "            generated_ids = output_.sequences\n",
    "            generated_ids = pad_across_processes(generated_ids, dim=1, pad_index=tokenizer.pad_token_id, pad_first=True)\n",
    "\n",
    "            labels = batch['generate_prefix_kwargs']['labels']\n",
    "            labels = pad_across_processes(labels, dim=1, pad_index=tokenizer.pad_token_id, pad_first=True)\n",
    "            labels[labels == -100] = tokenizer.pad_token_id\n",
    "\n",
    "            generated_ids, labels = accelerator.gather(generated_ids), accelerator.gather(labels)\n",
    "\n",
    "            preds = [\n",
    "                tokenizer.decode(g.cpu().numpy().tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=True).strip() for g in\n",
    "                generated_ids]\n",
    "            predictions.extend(preds)\n",
    "            target = [\n",
    "                tokenizer.decode(t.cpu().numpy().tolist(), skip_special_tokens=True, clean_up_tokenization_spaces=True).strip() for t in\n",
    "                labels]\n",
    "            targets.extend(target)\n",
    "\n",
    "        predictions = predictions[:len(dataset)]\n",
    "        targets = targets[:len(dataset)]\n",
    "    \n",
    "        if accelerator.is_main_process and accelerator.is_local_main_process:\n",
    "            # 打印输出、目标\n",
    "            accelerator.print(\"=\"*100)\n",
    "            accelerator.print(\"=\"*20,\"predictions\", \"=\"*20)\n",
    "            accelerator.print(predictions)\n",
    "            accelerator.print(\"=\"*20,\"targets\", \"=\"*20)\n",
    "            accelerator.print(targets)\n",
    "            accelerator.print(\"=\"*100)\n",
    "            \n",
    "            results = []\n",
    "            src_name = dataset[0]['item_id'].split('_')[0]\n",
    "            for pred, tar, item in zip(predictions, targets, dataset):\n",
    "                cur_res = {\n",
    "                    'item_id': item['item_id'],\n",
    "                    'answer_value': item['answer_value'],\n",
    "                }\n",
    "                ## Processing target\n",
    "                target_cot = tar.strip().split(cot_trigger)[-1].strip()\n",
    "                target_value = post_process_final_answer_fn_mapper[src_name](cur_res['answer_value'])\n",
    "                cur_res['target'] = target\n",
    "                cur_res['target_cot'] = target_cot\n",
    "                cur_res['target_value'] = target_value\n",
    "                ## Processing prediction\n",
    "                prediction_cot = pred.strip().split(cot_trigger)[-1].strip()\n",
    "                cur_res['prediction'] = pred\n",
    "                cur_res['prediction_cot'] = prediction_cot\n",
    "                cur_res['prediction_value'] = None # Tobe filled\n",
    "                results.append(cur_res)\n",
    "            print(\"=\"*100)\n",
    "            print(\"eval results:\")\n",
    "            print(results)\n",
    "            execute_fn = post_process_answer_cot_fn_mapper[(args['engine'], src_name)]\n",
    "            corr_value = 0\n",
    "            for i, prediction_value in enumerate(execute_fn([item['prediction_cot'] for item in results])):\n",
    "                target_value = results[i]['target_value']\n",
    "                is_correct = compare_answer_fn_mapper[src_name](prediction_value, target_value) if prediction_value is not None else False\n",
    "                results[i]['prediction_value'] = prediction_value\n",
    "                results[i]['is_correct'] = is_correct\n",
    "                corr_value += is_correct\n",
    "\n",
    "            res_path = args['model_dir'].rstrip('/')+ '/' + '_res.json'\n",
    "            with open(res_path, 'w') as f:\n",
    "                json.dump(results, f, indent=2)\n",
    "\n",
    "            # if args['wandb_log']:\n",
    "            #     table = wandb.Table(dataframe=pd.DataFrame(results))\n",
    "            #     wandb.log({\"predictions\": table})\n",
    "\n",
    "            value_accuracy = corr_value / len(results) * 100\n",
    "            accelerator.print(f\"[Eval Info] value_accuracy: {value_accuracy:.5g}%\")\n",
    "            value_accuracy = torch.FloatTensor([value_accuracy]).to(accelerator.device)\n",
    "        else:\n",
    "            value_accuracy = torch.FloatTensor([-1.0]).to(accelerator.device)\n",
    "        value_accuracy = broadcast(value_accuracy).cpu().numpy().tolist()[0]\n",
    "\n",
    "        # Metric summary:\n",
    "        model.train()\n",
    "        return {'value_accuracy': value_accuracy}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def training_loop(args):\n",
    "    accelerator = Accelerator(\n",
    "        deepspeed_plugin=args['deepspeed_plugin']\n",
    "    )\n",
    "    trainer = Trainer(accelerator)\n",
    "    \n",
    "    set_seed(args['seed'] + accelerator.process_index)\n",
    "    if torch.distributed.get_rank() == 0 and args['wandb_log']:\n",
    "        wandb.init(project=args['wandb_project'], name=args['wandb_run_name'])\n",
    "        wandb.config.update(args)\n",
    "        \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args['tokenizer_name_or_path'],\n",
    "        trust_remote_code=True,\n",
    "        padding_side='left',  # ChatGLM 使用左侧填充\n",
    "        eos_token='<|endoftext|>',  # 设置 EOS token\n",
    "        pad_token='<|endoftext|>',  # 设置 PAD token\n",
    "    )\n",
    "    \n",
    "    # 确保 tokenizer 有必要的特殊 token\n",
    "    special_tokens_dict = {\n",
    "        'pad_token': '<|endoftext|>',\n",
    "        'eos_token': '<|endoftext|>',\n",
    "        'bos_token': '<|startoftext|>',\n",
    "    }\n",
    "    tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "    (train_dataset, train_dataloader), (test_dataset, test_dataloader) = trainer.prepare_datasets_and_data_loaders(args, tokenizer)\n",
    "    config = AutoConfig.from_pretrained(\n",
    "        args['model_name_or_path'],\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # 添加缺失的配置\n",
    "    config._attn_implementation = \"eager\"  # 添加注意力实现方式\n",
    "    \n",
    "    # 加载模型\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        args['model_name_or_path'],\n",
    "        config=config,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    \n",
    "    # 确保模型参数是 bf16 类型\n",
    "    model = model.bfloat16()\n",
    "    \n",
    "    accelerator.print(f'[Vocab size]: {len(tokenizer)}')    \n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if accelerator.is_main_process and args['wandb_log']:\n",
    "        wandb.run.summary.update({\n",
    "            'pad_token_id': tokenizer.pad_token_id,\n",
    "            'eos_token_id': tokenizer.eos_token_id,\n",
    "            'unk_token_id': tokenizer.unk_token_id,\n",
    "            'vocab_size': len(tokenizer)\n",
    "        })\n",
    "\n",
    "    n_epochs = args['n_epochs']\n",
    "    num_training_steps = (len(train_dataloader) // accelerator.num_processes * n_epochs) // args['gradient_accumulation_steps']\n",
    "    warmup_step = args['warmup_step'] if args['warmup_step'] is not None and args['warmup_step'] >= 0 else int(0.1 * num_training_steps)\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in [\"bias\", \"LayerNorm.weight\"])],\n",
    "            \"weight_decay\": args['weight_decay'],\n",
    "        },\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in [\"bias\", \"LayerNorm.weight\"])],\n",
    "            \"weight_decay\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args['learning_rate'], eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=num_training_steps)\n",
    "    # scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step)\n",
    "    accelerator.print(\n",
    "        f\"***** Running training *****\\n\"\n",
    "        f\"  Num examples = {len(train_dataset)}\\n\"\n",
    "        f\"  Num Epochs = {n_epochs}\\n\"\n",
    "        f\"  Instantaneous batch size per device = {args['batch_size']}\\n\"\n",
    "        f\"  Total train batch size (w. parallel, distributed & accumulation) = {args['batch_size']*accelerator.num_processes*args['gradient_accumulation_steps']}\\n\"\n",
    "        f\"  Total optimization steps = {num_training_steps}\\n\"\n",
    "        f\"  Warm up step: {warmup_step}\\n\"\n",
    "        f\"  Learning rate: {args['learning_rate']}\\n\"\n",
    "    )   \n",
    "    model, optimizer, train_dataloader, test_dataloader = accelerator.prepare(model, optimizer, train_dataloader, test_dataloader)\n",
    "    \n",
    "    global_step = 0\n",
    "    evaluating_epoch_freq = args['evaluating_epoch_freq']\n",
    "    logging_epoch_freq = args['logging_epoch_freq']\n",
    "    saving_epoch_freq = args['saving_epoch_freq']\n",
    "    model_dir=args['model_dir']\n",
    "    best_eval_log_dict = {}\n",
    "    summary_log_dict = {}\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    most_recent_ckpts_paths = []\n",
    "    lowest_loss = None\n",
    "    with tqdm(range(1, n_epochs+1), total=n_epochs, disable=not accelerator.is_main_process) as t:\n",
    "        for epoch in t:\n",
    "            kwargs = {\n",
    "                'args': args,\n",
    "                'model': model, \n",
    "                'train_dataset': train_dataset, \n",
    "                'train_dataloader': train_dataloader, \n",
    "                'test_dataset': test_dataset,\n",
    "                'test_dataloader': test_dataloader,\n",
    "                'optimizer': optimizer, \n",
    "                'scheduler': scheduler,\n",
    "                'global_step': global_step, \n",
    "                'tokenizer': tokenizer,\n",
    "                'prefix':'', \n",
    "                'epoch': epoch,\n",
    "                'best_eval_log_dict': best_eval_log_dict,\n",
    "                'summary_log_dict': summary_log_dict,\n",
    "                'most_recent_ckpts_paths': most_recent_ckpts_paths,\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                train_epoch_result_dict, global_step, evaluate_result_dict = trainer.train_one_epoch(**kwargs)\n",
    "                accelerator.print(f\"[进程 {accelerator.process_index}] Epoch {epoch} 训练结果: {train_epoch_result_dict}\")\n",
    " \n",
    "            except Exception as e:\n",
    "                accelerator.print(f\"[进程 {accelerator.process_index}] Epoch {epoch} 发生错误: {e}\")\n",
    "                break\n",
    "            \n",
    "            eval_log_dict = {}\n",
    "            is_best = False\n",
    "            \n",
    "            accelerator.print(f'跳过evaluation')\n",
    "            # if evaluating_epoch_freq is not None and epoch % evaluating_epoch_freq == 0:\n",
    "            #     evaluate_result_dict = {f'Eval.Gen.{k}':  v for k, v in evaluate_generation(args, model, test_dataset, test_dataloader, tokenizer).items()}\n",
    "            #     eval_log_dict.update(evaluate_result_dict)\n",
    "            #     if eval_log_dict['Eval.Gen.value_accuracy'] > best_eval_log_dict.get('Eval.Gen.value_accuracy_best', 0):\n",
    "            #         is_best = True\n",
    "            #         best_eval_log_dict['Eval.Gen.value_accuracy_best'] = eval_log_dict['Eval.Gen.value_accuracy']\n",
    "            #     if 'Eval.Gen.value_accuracy' not in summary_log_dict:\n",
    "            #         summary_log_dict['Eval.Gen.value_accuracy'] = []\n",
    "            #     summary_log_dict['Eval.Gen.value_accuracy'].append(eval_log_dict['Eval.Gen.value_accuracy'])\n",
    "            if lowest_loss is None:\n",
    "                lowest_loss = train_epoch_result_dict[\"loss\"]\n",
    "                is_best = True\n",
    "            elif train_epoch_result_dict[\"loss\"] < lowest_loss:\n",
    "                lowest_loss = train_epoch_result_dict[\"loss\"]\n",
    "                is_best = True\n",
    "                \n",
    "            train_log_dict = {}\n",
    "            if logging_epoch_freq is not None and epoch % logging_epoch_freq == 0:\n",
    "                train_log_dict = {f'T.{k}': sum(v)/len(v) if isinstance(v, list) else v for k, v in train_epoch_result_dict.items()}\n",
    "\n",
    "            if eval_log_dict or train_log_dict:\n",
    "                log_dict = {'lr': scheduler.get_last_lr()[0], **train_log_dict, **eval_log_dict, **best_eval_log_dict}\n",
    "                if accelerator.is_main_process and args['wandb_log']:\n",
    "                    wandb.log(log_dict, step=global_step)\n",
    "                    log_dict = {'wandb': args['wandb_project'] + '|' + args['wandb_run_name'], **log_dict}\n",
    "                log_dict = {k: f'{v:.5g}' if isinstance(v, float) else v for k,v in log_dict.items()}\n",
    "                accelerator.print(f\"[E={epoch}/{args['n_epochs']}, S={global_step}] {log_dict}\")\n",
    "            \n",
    "            # if saving_epoch_freq is not None and epoch % saving_epoch_freq == 0:\n",
    "            if is_best:\n",
    "                try:\n",
    "                    accelerator.wait_for_everyone()\n",
    "                    accelerator.print(f\"epoch {epoch} 将开始保存权重，等待所有进程成功\")\n",
    "                except Exception as e:\n",
    "                    accelerator.print(f\"epoch {epoch} 将开始保存权重，等待所有进程失败: {e}\")\n",
    "                    break\n",
    "                \n",
    "                save_path = model_dir\n",
    "                # 如果目录已存在,先清空\n",
    "                if accelerator.is_main_process and os.path.exists(save_path):\n",
    "                    accelerator.print(f\"目录已存在, 清空目录: {save_path}\")\n",
    "                    # shutil.rmtree(save_path)\n",
    "                os.makedirs(save_path, exist_ok=True)\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                accelerator.print(f\"开始保存新的最佳checkpoint... 时间: {timestamp}\")\n",
    "                \n",
    "                # accelerator.wait_for_everyone()\n",
    "                s=trainer.do_checkpoint(args, model, tokenizer, save_path, global_step)\n",
    "                # accelerator.wait_for_everyone()\n",
    "                if s:\n",
    "                    accelerator.print(f\"保存checkpoint成功\")\n",
    "                else:\n",
    "                    accelerator.print(f\"保存checkpoint失败\")\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get args from shell script\n",
    "import re\n",
    "\n",
    "def parse_shell_script(script_path):\n",
    "    # 初始化参数和命令字典\n",
    "    params = {}\n",
    "    commands = {}\n",
    "    \n",
    "    # 读取shell脚本内容\n",
    "    with open(script_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # 解析每一行\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        \n",
    "        # 跳过空行和注释行\n",
    "        if not line or line.startswith('#'):\n",
    "            continue\n",
    "            \n",
    "        # 解析export命令\n",
    "        if line.startswith('export'):\n",
    "            match = re.match(r'export\\s+(\\w+)=(.+)', line)\n",
    "            if match:\n",
    "                key, value = match.groups()\n",
    "                commands[key] = value\n",
    "            continue\n",
    "            \n",
    "        # 解析参数赋值（形如 var=${var:-'default'} 或 var='value'）\n",
    "        match = re.match(r'(\\w+)=\\${?([^}]*)}?', line)\n",
    "        if match:\n",
    "            key, value = match.groups()\n",
    "            # 处理带有默认值的情况 ${var:-'default'}\n",
    "            if ':-' in value:\n",
    "                value = value.split(':-')[1].strip(\"'\\\"\")\n",
    "            params[key] = value\n",
    "            continue\n",
    "            \n",
    "        # 解析直接赋值（形如 var=value）\n",
    "        match = re.match(r'(\\w+)=[\\'\"]?([^\\'\"]*)[\\'\"]?', line)\n",
    "        if match:\n",
    "            key, value = match.groups()\n",
    "            params[key] = value\n",
    "            \n",
    "    return params, commands\n",
    "\n",
    "\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from transformers import HfArgumentParser\n",
    "\n",
    "NONE_INT = -100 \n",
    "NONE_STR = 'None'\n",
    "# 首先定义Arguments类（与你的代码中一致）\n",
    "@dataclass\n",
    "class Arguments:\n",
    "    model_name_or_path: str\n",
    "    tokenizer_name_or_path: str\n",
    "    model_dir: str\n",
    "    train_file: str \n",
    "    test_file: str\n",
    "    batch_size: int = field(default=4)\n",
    "    eval_batch_size: int = field(default=8)\n",
    "    n_epochs: int = field(default=40)\n",
    "    num_workers: int = field(default=8)\n",
    "    learning_rate: float = field(default=2e-5)\n",
    "    weight_decay: float = field(default=1e-6)\n",
    "    warmup_step: int = field(default=0)\n",
    "    clip_grad_norm: float = field(default=1)\n",
    "    evaluating_epoch_freq: int = field(default=1)\n",
    "    logging_epoch_freq: int = field(default=1)\n",
    "    saving_epoch_freq: int = field(default=1000)\n",
    "    evaluating_step_freq: int = field(default=NONE_INT)\n",
    "    logging_step_freq: int = field(default=NONE_INT)\n",
    "    saving_step_freq: int = field(default=NONE_INT)\n",
    "    seed: int = field(default=42)\n",
    "    max_input_length: int = field(default=700)\n",
    "    max_gen_length: int = field(default=512)\n",
    "    gradient_accumulation_steps: int = field(default=1)\n",
    "    keep_num_ckpt: int = field(default=1)\n",
    "    wandb_log: bool = field(default=False)\n",
    "    wandb_project: str = field(default='tmp_anvfupsadfn')\n",
    "    wandb_run_name: str = field(default='default_run_name')\n",
    "    engine: str = field(default='nl')\n",
    "\n",
    "# 解析Shell脚本并获取参数字典\n",
    "template_path = '/home/wangxinrong/workspace/reft/divination/mwp_ReFT/exps/paper_exps/SFT/_template.sh'\n",
    "zhouyi_path = '/home/wangxinrong/workspace/reft/divination/mwp_ReFT/exps/paper_exps/SFT/zhouyi_sft.sh'\n",
    "\n",
    "# 获取合并后的参数字典\n",
    "template_params, template_commands = parse_shell_script(template_path)\n",
    "zhouyi_params, zhouyi_commands = parse_shell_script(zhouyi_path)\n",
    "shell_params = {**template_params, **zhouyi_params}\n",
    "\n",
    "# 类型转换函数\n",
    "def convert_type(value, target_type):\n",
    "    if target_type == bool:\n",
    "        return value.lower() == 'true'\n",
    "    if target_type == int:\n",
    "        try:\n",
    "            return int(value)\n",
    "        except ValueError:\n",
    "            if value == 'None' or value == '-100':\n",
    "                return None\n",
    "            raise\n",
    "    if target_type == float:\n",
    "        try:\n",
    "            return float(value)\n",
    "        except ValueError:\n",
    "            if value == 'None':\n",
    "                return None\n",
    "            raise\n",
    "    return value\n",
    "\n",
    "# 创建符合Arguments类型的字典\n",
    "args = {}\n",
    "for field_name, field_def in Arguments.__dataclass_fields__.items():\n",
    "    if field_name in shell_params:\n",
    "        args[field_name] = convert_type(shell_params[field_name], field_def.type)\n",
    "    else:\n",
    "        # 使用默认值\n",
    "        args[field_name] = field_def.default\n",
    "\n",
    "# 处理特殊值（如果有的话）\n",
    "for k, v in args.items():\n",
    "    if v in [NONE_INT, 'None']:\n",
    "        args[k] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on 8 GPUs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[rank6]:[W109 16:16:34.216926984 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank1]:[W109 16:16:40.750114209 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['item_id', 'question', 'answer_cot', 'answer_value'],\n",
      "        num_rows: 16\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['item_id', 'question', 'answer_cot', 'answer_value'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n",
      "Using instruction: Question:\n",
      "\n",
      "Using cot_trigger: \n",
      "Answer reasoning:\n",
      "\n",
      "Using answer_trigger: \n",
      "因此，答案是：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank7]:[W109 16:16:41.764693545 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank2]:[W109 16:16:45.607773104 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank3]:[W109 16:16:46.294356444 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank5]:[W109 16:16:46.609203590 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "[rank4]:[W109 16:16:46.609519221 ProcessGroupNCCL.cpp:4115] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect.Specify device_ids in barrier() to force use of a particular device,or call init_process_group() with a device_id.\n",
      "Map (num_proc=8): 100%|██████████| 16/16 [00:16<00:00,  1.02s/ examples]\n",
      "Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7fb870b2ede0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/weakref.py\", line 105, in remove\n",
      "    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):\n",
      "\n",
      "  File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 84, in _terminate_process_handler\n",
      "    raise SignalException(f\"Process {os.getpid()} got signal: {sigval}\", sigval=sigval)\n",
      "torch.distributed.elastic.multiprocessing.api.SignalException: Process 3894424 got signal: 15\n",
      "[rank6]:[W109 16:26:34.564112167 socket.cpp:462] [c10d] waitForInput: poll for socket SocketImpl(fd=148, addr=[::ffff:127.0.0.1]:56726, remote=[::ffff:127.0.0.1]:29500) returned 0, likely a timeout\n",
      "[rank6]:[W109 16:26:34.566517723 socket.cpp:487] [c10d] waitForInput: socket SocketImpl(fd=148, addr=[::ffff:127.0.0.1]:56726, remote=[::ffff:127.0.0.1]:29500) timed out after 600000ms\n",
      "W0109 16:26:35.337000 3893964 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 3894128 via signal SIGTERM\n",
      "W0109 16:26:35.348000 3893964 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 3894135 via signal SIGTERM\n",
      "W0109 16:26:35.350000 3893964 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 3894142 via signal SIGTERM\n",
      "W0109 16:26:35.352000 3893964 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 3894147 via signal SIGTERM\n",
      "W0109 16:26:35.353000 3893964 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 3894164 via signal SIGTERM\n",
      "W0109 16:26:35.356000 3893964 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 3894176 via signal SIGTERM\n",
      "W0109 16:26:35.357000 3893964 site-packages/torch/multiprocessing/spawn.py:160] Terminating process 3894194 via signal SIGTERM\n",
      "W0109 16:27:05.391000 3893964 site-packages/torch/multiprocessing/spawn.py:168] Unable to shutdown process 3894135 via SIGTERM , forcefully exiting via SIGKILL\n",
      "W0109 16:27:05.541000 3893964 site-packages/torch/multiprocessing/spawn.py:168] Unable to shutdown process 3894142 via SIGTERM , forcefully exiting via SIGKILL\n",
      "W0109 16:27:05.673000 3893964 site-packages/torch/multiprocessing/spawn.py:168] Unable to shutdown process 3894147 via SIGTERM , forcefully exiting via SIGKILL\n",
      "W0109 16:27:05.993000 3893964 site-packages/torch/multiprocessing/spawn.py:168] Unable to shutdown process 3894164 via SIGTERM , forcefully exiting via SIGKILL\n",
      "W0109 16:27:06.450000 3893964 site-packages/torch/multiprocessing/spawn.py:168] Unable to shutdown process 3894176 via SIGTERM , forcefully exiting via SIGKILL\n",
      "W0109 16:27:07.126000 3893964 site-packages/torch/multiprocessing/spawn.py:168] Unable to shutdown process 3894194 via SIGTERM , forcefully exiting via SIGKILL\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] failed (exitcode: 1) local_rank: 6 (pid: 3894189) of fn: training_loop (start_method: fork)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] Traceback (most recent call last):\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 687, in _poll\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     self._pc.join(-1)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\", line 203, in join\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] torch.multiprocessing.spawn.ProcessRaisedException: \n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] \n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] -- Process 6 terminated with the following error:\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] Traceback (most recent call last):\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/multiprocessing/spawn.py\", line 90, in _wrap\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     fn(i, *args)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/api.py\", line 611, in _wrap\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     ret = record(fn)(*args_)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]           ^^^^^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     return f(*args, **kwargs)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]            ^^^^^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/tmp/ipykernel_3893964/3522858831.py\", line 29, in training_loop\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     (train_dataset, train_dataloader), (test_dataset, test_dataloader) = trainer.prepare_datasets_and_data_loaders(args, tokenizer)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/tmp/ipykernel_3893964/2319000155.py\", line 19, in prepare_datasets_and_data_loaders\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     with accelerator.main_process_first():\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/contextlib.py\", line 137, in __enter__\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     return next(self.gen)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]            ^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/accelerator.py\", line 920, in main_process_first\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     with self.state.main_process_first():\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/contextlib.py\", line 137, in __enter__\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     return next(self.gen)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]            ^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 1074, in main_process_first\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     with PartialState().main_process_first():\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/contextlib.py\", line 137, in __enter__\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     return next(self.gen)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]            ^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 496, in main_process_first\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     yield from self._goes_first(self.is_main_process)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 381, in _goes_first\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     self.wait_for_everyone()\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 375, in wait_for_everyone\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     torch.distributed.barrier()\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/c10d_logger.py\", line 83, in wrapper\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     return func(*args, **kwargs)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]            ^^^^^^^^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]   File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py\", line 4159, in barrier\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]     work = group.barrier(opts=opts)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732]            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] torch.distributed.DistBackendError: [6] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: wait timeout after 600000ms, keys: //worker/attempt_0/default_pg/0//cuda//0\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] Exception raised from doWait at /opt/conda/conda-bld/pytorch_1728945377988/work/torch/csrc/distributed/c10d/TCPStore.cpp:600 (most recent call first):\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fb8d6975446 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libc10.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #1: <unknown function> + 0x1327393 (0x7fb91b3c8393 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #2: c10d::TCPStore::doGet(std::string const&) + 0x2a (0x7fb91fdd6bca in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #3: c10d::TCPStore::get(std::string const&) + 0x7a (0x7fb91fdd7a3a in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #4: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xaf (0x7fb8d7c2fbff in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, c10::Device&, c10d::OpType, int, bool) + 0xfbd (0x7fb8d7c3bb9d in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #10: <unknown function> + 0x123a33e (0x7fb8d7c4433e in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #11: c10d::ProcessGroupNCCL::allreduce_impl(at::Tensor&, c10d::AllreduceOptions const&) + 0x12c (0x7fb8d7c4590c in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #12: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x476 (0x7fb8d7c531e6 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #13: <unknown function> + 0x5cd95f2 (0x7fb91fd7a5f2 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #14: <unknown function> + 0x5ce3df5 (0x7fb91fd84df5 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #15: <unknown function> + 0x52fd9bb (0x7fb91f39e9bb in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #16: <unknown function> + 0x52fb249 (0x7fb91f39c249 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #17: <unknown function> + 0x17d7c38 (0x7fb91b878c38 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #18: <unknown function> + 0x5cedc74 (0x7fb91fd8ec74 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #19: <unknown function> + 0x5ceea05 (0x7fb91fd8fa05 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #20: <unknown function> + 0xdfe698 (0x7fb930f13698 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_python.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #21: <unknown function> + 0x4cc1e3 (0x7fb9305e11e3 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_python.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #22: <unknown function> + 0x224588 (0x564e62709588 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #23: _PyObject_MakeTpCall + 0x2bb (0x564e626e975b in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #24: <unknown function> + 0x1126a1 (0x564e625f76a1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #25: <unknown function> + 0x27089d (0x564e6275589d in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #26: <unknown function> + 0x113768 (0x564e625f8768 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #27: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #28: <unknown function> + 0x114b20 (0x564e625f9b20 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #29: <unknown function> + 0x27089d (0x564e6275589d in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #30: <unknown function> + 0x113768 (0x564e625f8768 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #31: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #32: <unknown function> + 0x114b20 (0x564e625f9b20 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #33: <unknown function> + 0x27089d (0x564e6275589d in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #34: <unknown function> + 0x113768 (0x564e625f8768 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #35: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #36: <unknown function> + 0x114b20 (0x564e625f9b20 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #37: _PyObject_FastCallDictTstate + 0x1ee (0x564e626ec2fe in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #38: <unknown function> + 0x23229c (0x564e6271729c in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #39: _PyObject_MakeTpCall + 0x274 (0x564e626e9714 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #40: <unknown function> + 0x1126a1 (0x564e625f76a1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #41: _PyObject_FastCallDictTstate + 0x1ee (0x564e626ec2fe in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #42: _PyObject_Call_Prepend + 0x69 (0x564e627176b9 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #43: <unknown function> + 0x30364b (0x564e627e864b in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #44: _PyObject_Call + 0xb5 (0x564e6271a135 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #45: <unknown function> + 0x113339 (0x564e625f8339 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #46: PyEval_EvalCode + 0xa1 (0x564e6279f741 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #47: <unknown function> + 0x2d5ece (0x564e627baece in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #48: <unknown function> + 0x112f8e (0x564e625f7f8e in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #49: <unknown function> + 0x2d099f (0x564e627b599f in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #50: <unknown function> + 0x2d1c57 (0x564e627b6c57 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #51: <unknown function> + 0x113e38 (0x564e625f8e38 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #52: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #53: <unknown function> + 0x2515be (0x564e627365be in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #54: _PyObject_Call + 0x12b (0x564e6271a1ab in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #55: <unknown function> + 0x113339 (0x564e625f8339 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #56: <unknown function> + 0x2d099f (0x564e627b599f in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #57: <unknown function> + 0x8274 (0x7fb9573b2274 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #58: <unknown function> + 0x8a63 (0x7fb9573b2a63 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #59: <unknown function> + 0x222fbc (0x564e62707fbc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #60: <unknown function> + 0x34db0c (0x564e62832b0c in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #61: <unknown function> + 0x1c402e (0x564e626a902e in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] frame #62: <unknown function> + 0x21940b (0x564e626fe40b in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] . This may indicate a possible application crash on rank 0 or a network set up issue.\n",
      "E0109 16:27:07.467000 3893964 site-packages/torch/distributed/elastic/multiprocessing/api.py:732] \n"
     ]
    },
    {
     "ename": "ChildFailedError",
     "evalue": "\n============================================================\ntraining_loop FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2025-01-09_16:26:34\n  host      : HS-DSS8440-009\n  rank      : 6 (local_rank: 6)\n  exitcode  : 1 (pid: 3894189)\n  error_file: /tmp/torchelastic_u0zkmm7w/none_5u7n5yel/attempt_0/6/error.json\n  traceback : Traceback (most recent call last):\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n      return f(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^\n    File \"/tmp/ipykernel_3893964/3522858831.py\", line 29, in training_loop\n      (train_dataset, train_dataloader), (test_dataset, test_dataloader) = trainer.prepare_datasets_and_data_loaders(args, tokenizer)\n                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/tmp/ipykernel_3893964/2319000155.py\", line 19, in prepare_datasets_and_data_loaders\n      with accelerator.main_process_first():\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/contextlib.py\", line 137, in __enter__\n      return next(self.gen)\n             ^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/accelerator.py\", line 920, in main_process_first\n      with self.state.main_process_first():\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/contextlib.py\", line 137, in __enter__\n      return next(self.gen)\n             ^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 1074, in main_process_first\n      with PartialState().main_process_first():\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/contextlib.py\", line 137, in __enter__\n      return next(self.gen)\n             ^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 496, in main_process_first\n      yield from self._goes_first(self.is_main_process)\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 381, in _goes_first\n      self.wait_for_everyone()\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 375, in wait_for_everyone\n      torch.distributed.barrier()\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/c10d_logger.py\", line 83, in wrapper\n      return func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py\", line 4159, in barrier\n      work = group.barrier(opts=opts)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  torch.distributed.DistBackendError: [6] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: wait timeout after 600000ms, keys: //worker/attempt_0/default_pg/0//cuda//0\n  Exception raised from doWait at /opt/conda/conda-bld/pytorch_1728945377988/work/torch/csrc/distributed/c10d/TCPStore.cpp:600 (most recent call first):\n  frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fb8d6975446 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libc10.so)\n  frame #1: <unknown function> + 0x1327393 (0x7fb91b3c8393 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #2: c10d::TCPStore::doGet(std::string const&) + 0x2a (0x7fb91fdd6bca in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #3: c10d::TCPStore::get(std::string const&) + 0x7a (0x7fb91fdd7a3a in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #4: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xaf (0x7fb8d7c2fbff in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, c10::Device&, c10d::OpType, int, bool) + 0xfbd (0x7fb8d7c3bb9d in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #10: <unknown function> + 0x123a33e (0x7fb8d7c4433e in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #11: c10d::ProcessGroupNCCL::allreduce_impl(at::Tensor&, c10d::AllreduceOptions const&) + 0x12c (0x7fb8d7c4590c in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #12: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x476 (0x7fb8d7c531e6 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #13: <unknown function> + 0x5cd95f2 (0x7fb91fd7a5f2 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #14: <unknown function> + 0x5ce3df5 (0x7fb91fd84df5 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #15: <unknown function> + 0x52fd9bb (0x7fb91f39e9bb in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #16: <unknown function> + 0x52fb249 (0x7fb91f39c249 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #17: <unknown function> + 0x17d7c38 (0x7fb91b878c38 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #18: <unknown function> + 0x5cedc74 (0x7fb91fd8ec74 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #19: <unknown function> + 0x5ceea05 (0x7fb91fd8fa05 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #20: <unknown function> + 0xdfe698 (0x7fb930f13698 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_python.so)\n  frame #21: <unknown function> + 0x4cc1e3 (0x7fb9305e11e3 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_python.so)\n  frame #22: <unknown function> + 0x224588 (0x564e62709588 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #23: _PyObject_MakeTpCall + 0x2bb (0x564e626e975b in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #24: <unknown function> + 0x1126a1 (0x564e625f76a1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #25: <unknown function> + 0x27089d (0x564e6275589d in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #26: <unknown function> + 0x113768 (0x564e625f8768 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #27: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #28: <unknown function> + 0x114b20 (0x564e625f9b20 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #29: <unknown function> + 0x27089d (0x564e6275589d in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #30: <unknown function> + 0x113768 (0x564e625f8768 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #31: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #32: <unknown function> + 0x114b20 (0x564e625f9b20 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #33: <unknown function> + 0x27089d (0x564e6275589d in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #34: <unknown function> + 0x113768 (0x564e625f8768 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #35: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #36: <unknown function> + 0x114b20 (0x564e625f9b20 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #37: _PyObject_FastCallDictTstate + 0x1ee (0x564e626ec2fe in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #38: <unknown function> + 0x23229c (0x564e6271729c in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #39: _PyObject_MakeTpCall + 0x274 (0x564e626e9714 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #40: <unknown function> + 0x1126a1 (0x564e625f76a1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #41: _PyObject_FastCallDictTstate + 0x1ee (0x564e626ec2fe in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #42: _PyObject_Call_Prepend + 0x69 (0x564e627176b9 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #43: <unknown function> + 0x30364b (0x564e627e864b in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #44: _PyObject_Call + 0xb5 (0x564e6271a135 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #45: <unknown function> + 0x113339 (0x564e625f8339 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #46: PyEval_EvalCode + 0xa1 (0x564e6279f741 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #47: <unknown function> + 0x2d5ece (0x564e627baece in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #48: <unknown function> + 0x112f8e (0x564e625f7f8e in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #49: <unknown function> + 0x2d099f (0x564e627b599f in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #50: <unknown function> + 0x2d1c57 (0x564e627b6c57 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #51: <unknown function> + 0x113e38 (0x564e625f8e38 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #52: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #53: <unknown function> + 0x2515be (0x564e627365be in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #54: _PyObject_Call + 0x12b (0x564e6271a1ab in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #55: <unknown function> + 0x113339 (0x564e625f8339 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #56: <unknown function> + 0x2d099f (0x564e627b599f in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #57: <unknown function> + 0x8274 (0x7fb9573b2274 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so)\n  frame #58: <unknown function> + 0x8a63 (0x7fb9573b2a63 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so)\n  frame #59: <unknown function> + 0x222fbc (0x564e62707fbc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #60: <unknown function> + 0x34db0c (0x564e62832b0c in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #61: <unknown function> + 0x1c402e (0x564e626a902e in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #62: <unknown function> + 0x21940b (0x564e626fe40b in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  . This may indicate a possible application crash on rank 0 or a network set up issue.\n  \n============================================================",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mChildFailedError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeepspeed_plugin\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m deepspeed_plugin\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 使用notebook_launcher，只传入基本参数\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mnotebook_launcher\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining_loop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43margs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_processes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_processes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmixed_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixed_precision\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/launchers.py:245\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[0;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes, rdzv_backend, rdzv_endpoint, rdzv_conf, rdzv_id, max_restarts, monitor_interval, log_line_prefix_template)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;124m\"\u001b[39m, ELASTIC_LOG_LINE_PREFIX_TEMPLATE_PYTORCH_VERSION):\n\u001b[1;32m    244\u001b[0m         launch_config_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_line_prefix_template\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_line_prefix_template\n\u001b[0;32m--> 245\u001b[0m     \u001b[43melastic_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLaunchConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlaunch_config_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mentrypoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ProcessRaisedException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/launcher/api.py:138\u001b[0m, in \u001b[0;36melastic_launch.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlaunch_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_entrypoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/launcher/api.py:269\u001b[0m, in \u001b[0;36mlaunch_agent\u001b[0;34m(config, entrypoint, args)\u001b[0m\n\u001b[1;32m    262\u001b[0m     events\u001b[38;5;241m.\u001b[39mrecord(agent\u001b[38;5;241m.\u001b[39mget_event_succeeded())\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mis_failed():\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;66;03m# ChildFailedError is treated specially by @record\u001b[39;00m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;66;03m# if the error files for the failed children exist\u001b[39;00m\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;66;03m# @record will copy the first error (root cause)\u001b[39;00m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;66;03m# to the error file of the launcher process.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChildFailedError(\n\u001b[1;32m    270\u001b[0m             name\u001b[38;5;241m=\u001b[39mentrypoint_name,\n\u001b[1;32m    271\u001b[0m             failures\u001b[38;5;241m=\u001b[39mresult\u001b[38;5;241m.\u001b[39mfailures,\n\u001b[1;32m    272\u001b[0m         )\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreturn_values\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ChildFailedError:\n",
      "\u001b[0;31mChildFailedError\u001b[0m: \n============================================================\ntraining_loop FAILED\n------------------------------------------------------------\nFailures:\n  <NO_OTHER_FAILURES>\n------------------------------------------------------------\nRoot Cause (first observed failure):\n[0]:\n  time      : 2025-01-09_16:26:34\n  host      : HS-DSS8440-009\n  rank      : 6 (local_rank: 6)\n  exitcode  : 1 (pid: 3894189)\n  error_file: /tmp/torchelastic_u0zkmm7w/none_5u7n5yel/attempt_0/6/error.json\n  traceback : Traceback (most recent call last):\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 355, in wrapper\n      return f(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^\n    File \"/tmp/ipykernel_3893964/3522858831.py\", line 29, in training_loop\n      (train_dataset, train_dataloader), (test_dataset, test_dataloader) = trainer.prepare_datasets_and_data_loaders(args, tokenizer)\n                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/tmp/ipykernel_3893964/2319000155.py\", line 19, in prepare_datasets_and_data_loaders\n      with accelerator.main_process_first():\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/contextlib.py\", line 137, in __enter__\n      return next(self.gen)\n             ^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/accelerator.py\", line 920, in main_process_first\n      with self.state.main_process_first():\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/contextlib.py\", line 137, in __enter__\n      return next(self.gen)\n             ^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 1074, in main_process_first\n      with PartialState().main_process_first():\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/contextlib.py\", line 137, in __enter__\n      return next(self.gen)\n             ^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 496, in main_process_first\n      yield from self._goes_first(self.is_main_process)\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 381, in _goes_first\n      self.wait_for_everyone()\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/accelerate/state.py\", line 375, in wait_for_everyone\n      torch.distributed.barrier()\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/c10d_logger.py\", line 83, in wrapper\n      return func(*args, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^\n    File \"/home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/distributed/distributed_c10d.py\", line 4159, in barrier\n      work = group.barrier(opts=opts)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  torch.distributed.DistBackendError: [6] is setting up NCCL communicator and retrieving ncclUniqueId from [0] via c10d key-value store by key '0', but store->get('0') got error: wait timeout after 600000ms, keys: //worker/attempt_0/default_pg/0//cuda//0\n  Exception raised from doWait at /opt/conda/conda-bld/pytorch_1728945377988/work/torch/csrc/distributed/c10d/TCPStore.cpp:600 (most recent call first):\n  frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x96 (0x7fb8d6975446 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libc10.so)\n  frame #1: <unknown function> + 0x1327393 (0x7fb91b3c8393 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #2: c10d::TCPStore::doGet(std::string const&) + 0x2a (0x7fb91fdd6bca in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #3: c10d::TCPStore::get(std::string const&) + 0x7a (0x7fb91fdd7a3a in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #4: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #5: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #6: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #7: c10d::PrefixStore::get(std::string const&) + 0x31 (0x7fb91fd87dc1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #8: c10d::ProcessGroupNCCL::broadcastUniqueNCCLID(ncclUniqueId*, bool, std::string const&, int) + 0xaf (0x7fb8d7c2fbff in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #9: c10d::ProcessGroupNCCL::getNCCLComm(std::string const&, c10::Device&, c10d::OpType, int, bool) + 0xfbd (0x7fb8d7c3bb9d in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #10: <unknown function> + 0x123a33e (0x7fb8d7c4433e in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #11: c10d::ProcessGroupNCCL::allreduce_impl(at::Tensor&, c10d::AllreduceOptions const&) + 0x12c (0x7fb8d7c4590c in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #12: c10d::ProcessGroupNCCL::barrier(c10d::BarrierOptions const&) + 0x476 (0x7fb8d7c531e6 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cuda.so)\n  frame #13: <unknown function> + 0x5cd95f2 (0x7fb91fd7a5f2 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #14: <unknown function> + 0x5ce3df5 (0x7fb91fd84df5 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #15: <unknown function> + 0x52fd9bb (0x7fb91f39e9bb in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #16: <unknown function> + 0x52fb249 (0x7fb91f39c249 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #17: <unknown function> + 0x17d7c38 (0x7fb91b878c38 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #18: <unknown function> + 0x5cedc74 (0x7fb91fd8ec74 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #19: <unknown function> + 0x5ceea05 (0x7fb91fd8fa05 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_cpu.so)\n  frame #20: <unknown function> + 0xdfe698 (0x7fb930f13698 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_python.so)\n  frame #21: <unknown function> + 0x4cc1e3 (0x7fb9305e11e3 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/site-packages/torch/lib/libtorch_python.so)\n  frame #22: <unknown function> + 0x224588 (0x564e62709588 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #23: _PyObject_MakeTpCall + 0x2bb (0x564e626e975b in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #24: <unknown function> + 0x1126a1 (0x564e625f76a1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #25: <unknown function> + 0x27089d (0x564e6275589d in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #26: <unknown function> + 0x113768 (0x564e625f8768 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #27: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #28: <unknown function> + 0x114b20 (0x564e625f9b20 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #29: <unknown function> + 0x27089d (0x564e6275589d in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #30: <unknown function> + 0x113768 (0x564e625f8768 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #31: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #32: <unknown function> + 0x114b20 (0x564e625f9b20 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #33: <unknown function> + 0x27089d (0x564e6275589d in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #34: <unknown function> + 0x113768 (0x564e625f8768 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #35: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #36: <unknown function> + 0x114b20 (0x564e625f9b20 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #37: _PyObject_FastCallDictTstate + 0x1ee (0x564e626ec2fe in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #38: <unknown function> + 0x23229c (0x564e6271729c in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #39: _PyObject_MakeTpCall + 0x274 (0x564e626e9714 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #40: <unknown function> + 0x1126a1 (0x564e625f76a1 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #41: _PyObject_FastCallDictTstate + 0x1ee (0x564e626ec2fe in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #42: _PyObject_Call_Prepend + 0x69 (0x564e627176b9 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #43: <unknown function> + 0x30364b (0x564e627e864b in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #44: _PyObject_Call + 0xb5 (0x564e6271a135 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #45: <unknown function> + 0x113339 (0x564e625f8339 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #46: PyEval_EvalCode + 0xa1 (0x564e6279f741 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #47: <unknown function> + 0x2d5ece (0x564e627baece in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #48: <unknown function> + 0x112f8e (0x564e625f7f8e in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #49: <unknown function> + 0x2d099f (0x564e627b599f in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #50: <unknown function> + 0x2d1c57 (0x564e627b6c57 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #51: <unknown function> + 0x113e38 (0x564e625f8e38 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #52: <unknown function> + 0x251adc (0x564e62736adc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #53: <unknown function> + 0x2515be (0x564e627365be in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #54: _PyObject_Call + 0x12b (0x564e6271a1ab in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #55: <unknown function> + 0x113339 (0x564e625f8339 in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #56: <unknown function> + 0x2d099f (0x564e627b599f in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #57: <unknown function> + 0x8274 (0x7fb9573b2274 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so)\n  frame #58: <unknown function> + 0x8a63 (0x7fb9573b2a63 in /home/wangxinrong/miniconda3/envs/cuda-12.2/lib/python3.12/lib-dynload/_asyncio.cpython-312-x86_64-linux-gnu.so)\n  frame #59: <unknown function> + 0x222fbc (0x564e62707fbc in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #60: <unknown function> + 0x34db0c (0x564e62832b0c in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #61: <unknown function> + 0x1c402e (0x564e626a902e in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  frame #62: <unknown function> + 0x21940b (0x564e626fe40b in /home/wangxinrong/miniconda3/envs/cuda-12.2/bin/python)\n  . This may indicate a possible application crash on rank 0 or a network set up issue.\n  \n============================================================"
     ]
    }
   ],
   "source": [
    "from accelerate.commands.config import load_config_from_file\n",
    "from accelerate.utils import DeepSpeedPlugin\n",
    "from accelerate import Accelerator\n",
    "from accelerate import notebook_launcher\n",
    "\n",
    "# 使用完整路径\n",
    "config_path = \"/home/hanxianlin/workspace/reft/divination/mwp_ReFT/default_config_deepspeed_ga2.yaml\"\n",
    "config = load_config_from_file(config_path)\n",
    "deepspeed_config = config.deepspeed_config\n",
    "\n",
    "# 创建DeepSpeedPlugin实例\n",
    "deepspeed_plugin = DeepSpeedPlugin(\n",
    "    zero_stage=deepspeed_config['zero_stage'],\n",
    "    gradient_accumulation_steps=deepspeed_config['gradient_accumulation_steps'],\n",
    "    gradient_clipping=deepspeed_config['gradient_clipping'],\n",
    "    offload_optimizer_device=deepspeed_config['offload_optimizer_device'],\n",
    "    offload_param_device=deepspeed_config['offload_param_device'],\n",
    ")\n",
    "\n",
    "args['deepspeed_plugin'] = deepspeed_plugin\n",
    "# 使用notebook_launcher，只传入基本参数\n",
    "notebook_launcher(\n",
    "    training_loop, \n",
    "    [args], \n",
    "    num_processes=config.num_processes,\n",
    "    mixed_precision=config.mixed_precision\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
